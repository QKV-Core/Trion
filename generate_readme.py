import os

def create_readme():
    print("ğŸ“ TRION CORE: README.md dosyasÄ± hazÄ±rlanÄ±yor...")
    
    # TÃ¼m iÃ§eriÄŸi tek bir raw string (r"...") iÃ§ine alÄ±yoruz.
    # BÃ¶ylece Python hiÃ§bir Ã¶zel karakteri (ters taksim, tÄ±rnak vs.) karÄ±ÅŸtÄ±rmaz.
    
    content = r"""<div align="center">

# ğŸ’  TRION CORE
### The 1.58-bit High-Performance LLM Engine

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Engine](https://img.shields.io/badge/engine-1.58--bit-magenta.svg)](qkv_core/)

*Ultra-dÃ¼ÅŸÃ¼k bellek kullanÄ±mÄ±, yÃ¼ksek hÄ±z ve matematiksel zeka.*

[Ã–zellikler](#-Ã¶zellikler) â€¢ [Kurulum](#-kurulum) â€¢ [Matematik](#-matematiksel-altyapÄ±) â€¢ [Mimari](#-sistem-mimarisi)

</div>

---

## ğŸš€ Proje HakkÄ±nda
**Trion Core**, BitNet b1.58 mimarisini temel alan, yeni nesil bir BÃ¼yÃ¼k Dil Modeli (LLM) Ã§ekirdeÄŸidir. Standart modellerin aksine, aÄŸÄ±rlÄ±klarÄ± (weights) 16-bit FP16 yerine **1.58-bit {-1, 0, 1}** deÄŸerlerinde saklar.

Bu devrimsel yaklaÅŸÄ±m sayesinde:
* **HafÄ±za (VRAM) kullanÄ±mÄ± %70 azalÄ±r.**
* **Matris Ã§arpÄ±mlarÄ± (MatMul), toplama iÅŸlemine (Addition) indirgenir.**
* **EÄŸitim sÃ¼resi ve enerji tÃ¼ketimi radikal biÃ§imde dÃ¼ÅŸer.**

---

## ğŸ§® Matematiksel AltyapÄ±

Trion Core, aÄŸÄ±rlÄ±klarÄ± sÄ±kÄ±ÅŸtÄ±rmak iÃ§in **Absmean Quantization** tekniÄŸini kullanÄ±r.

### 1. Kuantizasyon FormÃ¼lÃ¼
AÄŸÄ±rlÄ±k matrisi $W$ iÃ§in Ã¶lÃ§ekleme faktÃ¶rÃ¼ $\gamma$ ve kuantize aÄŸÄ±rlÄ±k $W_{quant}$ ÅŸÃ¶yle hesaplanÄ±r:

$$ \gamma = \frac{1}{nm} \sum_{ij} |W_{ij}| $$

$$ W_{quant} = \text{Clip}\left(\text{Round}\left(\frac{W}{\gamma}\right), -1, 1\right) $$

SonuÃ§ olarak $W_{quant}$ matrisi sadece $\{-1, 0, +1\}$ deÄŸerlerini iÃ§erir.

### 2. Ä°leri Besleme (Forward Pass)
Aktivasyonlar $X$, 8-bit hassasiyetine Ã¶lÃ§eklenir:

$$ Y = (W_{quant} \times X_{quant}) \times \frac{\gamma \beta}{Q_b} $$

Burada iÅŸlem, aÄŸÄ±r matris Ã§arpÄ±mÄ± yerine **Sparse Addition** (Seyrek Toplama) iÅŸlemine dÃ¶nÃ¼ÅŸÃ¼r.

---

## ğŸ—ï¸ Sistem Mimarisi

Trion Core veri akÄ±ÅŸ ÅŸemasÄ± (Mermaid):

```mermaid
graph TD
    A[Input Text] -->|Tokenizer| B(Token IDs)
    B --> C{Trion Embedding}
    C -->|FP32| D[Layer 1: BitGhostBlock]
    D -->|RMSNorm| E[Attention Mechanism]
    E -->|Identity Init| F[MLP: 1.58-bit Linear]
    F -->|BitQuant| G[Layer N...]
    G --> H[RMSNorm Final]
    H --> I[Output Head]
    I -->|Logits| J[Next Token Prediction]
    
    style C fill:#222,stroke:#00bcd4,stroke-width:2px
    style F fill:#440000,stroke:#ff0000,stroke-width:2px
    style I fill:#222,stroke:#00bcd4,stroke-width:2px