import torch
import torch.nn as nn
import os
import math
import sys

# Trion Core ModÃ¼llerini Ã‡ek
try:
    from trion_core.modeling import QKVModel, QKVConfig
except ImportError:
    print("âŒ HATA: 'qkv_core' klasÃ¶rÃ¼ bulunamadÄ±.")
    sys.exit()

def calculate_trion_brain():
    print("ğŸ“ TRION CORE: Statik Beyin Ä°nÅŸasÄ± BaÅŸlatÄ±lÄ±yor...")
    print("   -> Hedef: Rastgelelikten arÄ±ndÄ±rÄ±lmÄ±ÅŸ, matematiksel denge.")

    # 1. TRION MÄ°MARÄ°SÄ° (GPT-2 Small StandartlarÄ±)
    config = QKVConfig(
        vocab_size=50257,  # GPT-2 SÃ¶zlÃ¼ÄŸÃ¼
        d_model=768,       # Standart GeniÅŸlik
        n_layer=12,        # Derinlik
        n_head=12,         # Dikkat KafalarÄ±
        max_seq_len=1024,
        attn_threshold=-0.1 
    )
    
    model = QKVModel(config)
    print(f"âš™ï¸  Ä°skelet HazÄ±r: {config.d_model}x{config.n_layer} Katman")

    # 2. MATEMATÄ°KSEL ENJEKSÄ°YON (Weight Engineering)
    print("ğŸ’‰ Matrislere 'Identity' ve 'Xavier' hesaplamalarÄ± uygulanÄ±yor...")
    
    with torch.no_grad():
        # A) Embedding (Kelime VektÃ¶rleri)
        # Ã‡ok dÃ¼ÅŸÃ¼k varyanslÄ± normal daÄŸÄ±lÄ±m (Kelimeler karÄ±ÅŸmasÄ±n diye)
        nn.init.normal_(model.token_embedding.weight, mean=0.0, std=0.02)
        model.position_embedding.weight.data.fill_(0.0) # Pozisyon baÅŸta nÃ¶tr olsun

        for i, layer in enumerate(model.layers):
            # B) ATTENTION (Ä°letiÅŸim)
            # Identity Matrix: Girdi = Ã‡Ä±ktÄ± (Ayna Etkisi)
            # Bu, modelin eÄŸitimsizken saÃ§malamasÄ±nÄ± engeller.
            nn.init.eye_(layer.attn.q_proj.weight)
            nn.init.eye_(layer.attn.k_proj.weight)
            nn.init.eye_(layer.attn.v_proj.weight)
            
            # Ã‡Ä±kÄ±ÅŸ projeksiyonunu sÄ±fÄ±ra yakÄ±n tutuyoruz ki gÃ¼rÃ¼ltÃ¼ birikmesin
            nn.init.normal_(layer.attn.o_proj.weight, std=0.001)

            # C) MLP (DÃ¼ÅŸÃ¼nme) - 1.58-bit Kritik BÃ¶lge
            # Kaiming Initialization: AktivasyonlarÄ±n sÃ¶nmemesi iÃ§in kazanÃ§ (Gain) hesabÄ±
            # 1.58 bit olduÄŸu iÃ§in sinyali biraz gÃ¼Ã§lendiriyoruz (Gain=sqrt(2))
            nn.init.kaiming_normal_(layer.mlp.fc1.weight, mode='fan_in', nonlinearity='relu')
            nn.init.kaiming_normal_(layer.mlp.fc2.weight, mode='fan_in', nonlinearity='relu')
            
            # Katman NormalizasyonlarÄ±nÄ± (RMSNorm) nÃ¶trle
            layer.ln1.weight.data.fill_(1.0)
            layer.ln2.weight.data.fill_(1.0)
            
            if i % 3 == 0: print(f"   -> Katman {i} stabilize edildi.")

        # D) Output Head (Kafa)
        # GiriÅŸ ile Ã§Ä±kÄ±ÅŸ matrisini baÄŸlÄ±yoruz (Weight Tying)
        model.output_head.weight = model.token_embedding.weight

    # 3. KAYIT
    filename = "trion_brain.pt"
    torch.save(model.state_dict(), filename)
    size_mb = os.path.getsize(filename) / (1024 * 1024)

    print("-" * 50)
    print(f"âœ… TRION BEYNÄ° OLUÅTURULDU: {filename}")
    print(f"ğŸ“Š Boyut: {size_mb:.2f} MB")
    print("ğŸ§  Durum: 'Tabula Rasa' (Temiz Levha)")
    print("   -> Bu model artÄ±k gÃ¼rÃ¼ltÃ¼ (Ã§Ã¶p karakter) Ã¼retmez.")
    print("   -> EÄŸitime baÅŸladÄ±ÄŸÄ±nda Ã§ok hÄ±zlÄ± Ã¶ÄŸrenir.")
    print("-" * 50)

if __name__ == "__main__":
    calculate_trion_brain()